{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://pbs.twimg.com/media/E0m6c9FX0AIX0p1.png\" style=\"height:200px\" align=\"left\"/> <br><br><br><br>\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "### **Exploring GEOROC 2.0:** <br/> Data Access, Formatting, and Visualization for Geochemical Analysis\n",
    "\n",
    "***\n",
    "\n",
    "<div style=\"text-align: justify; max-width: 850px\">\n",
    "The GEOROC Database (Geochemistry of Rocks of the Oceans and Continents) is a comprehensive collection of published analyses of igneous and metamorphic rocks and minerals. It contains major and trace element concentrations, radiogenic and nonradiogenic isotope ratios as well as analytical ages for whole rocks, glasses, minerals and inclusions. Metadata include geospatial and other sample information, analytical details and references.\n",
    "\n",
    "The GEOROC Database was established at the Max Planck Institute for Chemistry in Mainz (Germany). In 2021, the database was moved to Göttingen University, where it continues to be curated as part of the DIGIS project of the Department of Geochemistry and Isotope Geology at the Geoscience Centre (GZG) and the University and State Library (SUB). Development for GEOROC 2.0 includes a new data model for greater interoperability, options to contribute data, and improved access to the database.\n",
    "\n",
    "As part of the DIGIS project, a new API interface has been created for the GEOROC database, allowing easy access to its contents with simple programming skills. Users can now query the database and retrieve data using the new API, making it more accessible and useful for researchers and other interested parties. This notebook demonstrates the basic capabilities of GEOROC data access <br/> via the new DIGIS API. \n",
    "\n",
    "For feedback, questions and further information contact [DIGIS-Info](mailto:digis-info@uni-goettingen.de) directly.\n",
    "\n",
    "This notebook demonstrates the basic capabilities of common data cleaning methods in geoscience.\n",
    "</div>\n",
    "\n",
    "***\n",
    "\n",
    "June 2023, Marthe Klöcking, Timm M. Wirtz\n",
    "\n",
    "<img src=\"https://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc-sa.png\" style=\"height:50px\" align=\"left\"/> <br><br>\n",
    "\n",
    "https://creativecommons.org/licenses/by-nc-sa/4.0/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"table\"></a>Table of contents\n",
    "\n",
    "* [Import modules](#import)\n",
    "* [Store your API key](#store)\n",
    "        * [Hint](#hint)\n",
    "* [Select the data that should be in the dataset](#select)\n",
    "        * [Hint](#hint2)\n",
    "* [Check if there is a connection to the API](#check)\n",
    "* [Select the filters to search for desired data](#filters)\n",
    "* [Extract the necessary SampleID's](#extract1)\n",
    "* [The raw dataset](#rawdata)\n",
    "* [Extract all the data using the SampleID's](#extract2)\n",
    "* [Sort columns](#sort-columns)\n",
    "* [Structure and pivot the dataset](#strucdata)\n",
    "* [Plot the data on a map](#plotmap)\n",
    "* [Plot FeO* against S](#plotfeotS)\n",
    "        * [Hint](#hint4)\n",
    "* [Plot the data in the TAS diagram](#plottas)\n",
    "        * [Hint](#hint5)\n",
    "* [Excursion - API download to CSV](#api-download)\n",
    "* [Excursion - EarthChem API](#excursion)\n",
    "* [References](#refs)\n",
    "* [QR code for accessing this Jupyter notebook](#qrcode)\n",
    "        * [Hint](#hint3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a name=\"import\"></a>Import modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; max-width: 850px\">\n",
    "\n",
    "**requests**: This module allows you to send HTTP requests and handle responses in Python. It is commonly used for making API calls and retrieving data from web servers.\n",
    "\n",
    "**json**: The JSON module provides functions to work with JSON data. It allows you to serialize Python objects into JSON strings and deserialize JSON strings into Python objects.\n",
    "\n",
    "**pandas**: The pandas library is a powerful tool for data manipulation and analysis. It provides data structures and functions for efficiently working with structured data, such as tables or spreadsheets.\n",
    "\n",
    "**geopandas**: Geopandas is an extension of the pandas library that adds support for geospatial data analysis. It provides data structures and functions for working with geographic data, such as maps, spatial joins, and geometric operations.\n",
    "\n",
    "**seaborn**: Seaborn is a data visualization library based on matplotlib. It provides a high-level interface for creating attractive and informative statistical graphics.\n",
    "\n",
    "**matplotlib.pyplot**: Matplotlib is a comprehensive plotting library in Python. It provides a wide range of functionalities for creating static, animated, and interactive visualizations.\n",
    "\n",
    "**matplotlib.patches.Ellipse**: The Ellipse module in matplotlib.patches allows you to draw ellipses on plots. It is useful for representing uncertainties or confidence intervals in data visualizations.\n",
    "\n",
    "**matplotlib.image**: The matplotlib.image module in Python's Matplotlib library offers functions for working with image data. It facilitates tasks such as loading, displaying, and manipulating images within Matplotlib figures, enabling seamless integration of images into visualizations.\n",
    "\n",
    "**matplotlib.gridspec.GridSpec**: The GridSpec module in Matplotlib allows for the creation of custom grid layouts for subplots. It provides a flexible and convenient way to specify the number of rows and columns in a grid, as well as the positioning of individual subplots within the grid.\n",
    "\n",
    "**contextily**: Contextily is a Python library that adds web map tiles as a background to matplotlib plots. It makes it easy to include basemaps from popular mapping providers, such as OpenStreetMap or Stamen, in your visualizations.\n",
    "\n",
    "**adjust_text**: The adjust_text module provides functions for automatically adjusting the position of text labels in a plot to prevent overlaps. It is particularly useful when you have many data points and want to ensure that the labels are readable.\n",
    "\n",
    "**widgets**: The widgets module in ipywidgets provides interactive user interface elements, such as sliders, buttons, and dropdown menus,  for Jupyter notebooks. It allows you to create interactive data exploration and visualization tools.\n",
    "\n",
    "**Layout**: The Layout module in ipywidgets allows you to customize the layout and styling of the widgets. It provides options for controlling the size, alignment, and spacing of the widgets in the user interface.\n",
    "\n",
    "**IntProgress, HBox, Label**: These are specific widget classes in ipywidgets. IntProgress is a widget for displaying a progress bar, HBox is a container widget that arranges its children horizontally, and Label is a widget for displaying text or a description.\n",
    "\n",
    "**Button**: The Button widget in ipywidgets allows you to create clickable buttons in the user interface. It is commonly used for triggering actions or functions when clicked.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.patches import Ellipse\n",
    "import contextily as ctx\n",
    "from adjustText import adjust_text\n",
    "from ipywidgets import widgets\n",
    "from ipywidgets import Layout\n",
    "from ipywidgets import IntProgress, Layout, HBox, Label\n",
    "from IPython.display import display\n",
    "from ipywidgets import Button\n",
    "from functions.widgets import *\n",
    "from functions.georoc_api import GeoRocAPI\n",
    "from functions.api import ApiKey\n",
    "from functions.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a name=\"store\"></a> Store your API key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; max-width: 850px\">\n",
    "\n",
    "In order to access data from the GeoRoc database, you need to obtain and use an API key. This API key acts as an access credential, functioning as both a unique identifier and a secure means of accessing the API.\n",
    "\n",
    "Here's how it works:\n",
    "\n",
    "- You first need to obtain an API key from the GeoRoc database provider. This process often involves registering your application with the provider and agreeing to their terms of use.\n",
    "\n",
    "- Once you have obtained your API key, you must store and handle it securely. In this Python application, the API key is stored in an instance of the ApiKey class. This is done by entering the API key into a password field, which hides the key on the screen for security reasons.\n",
    "\n",
    "- The 'Save' button then triggers a function to save the API key and establish a connection with the GeoRoc database.\n",
    "\n",
    "Remember, it's crucial to keep your API key confidential. Exposure can lead to unauthorized access to your data on the GeoRoc database, data corruption or even denial of access if the provider detects misuse.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_api = ApiKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a name=\"hint\"></a>Hint:\n",
    "- It is necessary to deposit the API and press the button so that it can be transferred."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a name=\"select\"></a> Select the data that should be in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; max-width: 850px\">\n",
    "\n",
    "Each of these keys correspond to a specific type of data you can access and retrieve from the GeoRoc database. For instance, if you are conducting a study on rock types in different tectonic settings, you might be specifically interested in the 'Rock_Types' and 'Tectonic_Setting' fields. By selecting these specific keys, you can customize the data you retrieve from the GeoRoc database to fit your particular research needs.\n",
    "\n",
    "The variety of fields available allows users to retrieve a wide array of geochemical, geolocation, and other related data for a multitude of potential geological studies. This makes the GeoRoc database a flexible and valuable tool for researchers in the field.\n",
    "\n",
    "For a more detailed insight, you can visit our [API Documentation](https://api-test.georoc.eu/api/v1/docs/index.html#/).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE (2024-08-28)\n",
    "the above code is deprecated. \n",
    "Until we have time to fix it, please manually define your search keys instead. \n",
    "\n",
    "For options, see response body to <https://api-test.georoc.eu/api/v1/docs/index.html#/fulldata/get_queries_fulldata>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search keys for sample/analysis attributes (metadata) and data\n",
    "selected_keys_metadata = ['sampleName', 'latitude', 'longitude']\n",
    "selected_keys_data = ['itemName', 'itemGroup', 'value', 'unit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a name=\"hint2\"></a>Hint:\n",
    "\n",
    "<div style=\"text-align: justify; max-width: 850px\">\n",
    "\n",
    "- It is necessary to specify the appropriate selection. Please use here:  **SampleName**, **Longitude**, **Latitude**, **Item_Name**, **Item_Group**, **Units** and **Values**.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a name=\"check\"></a>Check if there is a connection to the API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; max-width: 850px\">\n",
    "\n",
    "The provided code checks the connection to the API. It ensures that the connection to the new GEOROC database interface of the DIGIS project can be established successfully. The code sends a request to the \"ping\" endpoint of the API and checks the received response. If the connection is successful, a success message is displayed. Otherwise, an error message is shown. This code is important to ensure a successful connection before performing any further actions with the GEOROC database.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to check the API connection\n",
    "def check_api_connection():\n",
    "    # Set the API endpoint to \"ping\"\n",
    "    endpoint = \"ping\"\n",
    "    \n",
    "    # Make an API query to the specified endpoint\n",
    "    response = my_api.api.api_query(endpoint)\n",
    "    \n",
    "    # Check if the response is not None\n",
    "    if response is not None:\n",
    "        print(\"Connection to API server successful!\\n\")\n",
    "    else:\n",
    "        print(\"Failed to connect to API server!\\n\")\n",
    "        exit(1)\n",
    "\n",
    "# Call the check_api_connection function\n",
    "check_api_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a name=\"filters\"></a> Select the filters to search for desired data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; max-width: 850px\">\n",
    "\n",
    "This interface provides a convenient way for you to filter and retrieve specific data from the GeoRoc database. Each box represents a different parameter you can specify to narrow down your search:\n",
    "\n",
    "- **Limit** and **Offset**: Choose how many records to retrieve and where to start.\n",
    "- **Location**: Enter up to three specific locations to focus your search geographically.\n",
    "- **Setting**: Specify the geological setting of the samples.\n",
    "- **Latitude** and **Longitude**: Narrow down your search by geographical coordinates.\n",
    "- **Rocktype**, **Rockclass**, **Mineral** and **Material**: Filter the samples based on their physical and chemical properties.\n",
    "- **SampleTech**: Indicate the technique used for sample collection.\n",
    "\n",
    "By using these tools, you can customize your data query to fit your exact needs, saving you time and effort in sifting through the database.\n",
    "\n",
    "In this case, tailored for the notebook, we exclusively use the following DOI: <br/> **\"10.1029/JB094iB08p10525\"** - Enter the DOI without quotation marks.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(grid2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Table of contects](#table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a name=\"extract1\"></a>Extract the necessary SampleID's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; max-width: 850px\">\n",
    "\n",
    "The code starts by calling the get_filtered_samples() method of the my_app.api object with various specified parameters. These parameters allow users to customize their queries and filter the samples based on different criteria such as location, rock type, mineral, and more.\n",
    "\n",
    "The code then checks if the key \"Data\" exists in the filtered_samples_combined dictionary. If it exists, the code prints each item in the list of dictionaries under the \"Data\" key, providing a view of the retrieved sample data. If the key does not exist or the data structure is unexpected, an appropriate error message is displayed.\n",
    "\n",
    "Additionally, the code checks if the key \"Data\" exists and if its value is not empty. If these conditions are met, the code extracts the \"SampleID\" values from the list of dictionaries in the \"Data\" key. The extracted sample IDs are then printed, organized in groups of 10 with a line break after each group.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the get_filtered_samples method of the my_app.api object with the specified parameters\n",
    "filtered_samples_combined = my_api.api.get_filtered_samples(\n",
    "    limit=limit_widget.value,\n",
    "    offset=offset_widget.value,\n",
    "    location1=location1_widget.value,\n",
    "    location2=location2_widget.value,\n",
    "    location3=location3_widget.value,\n",
    "    setting=setting_widget.value,\n",
    "    latitude=latitude_widget.value,\n",
    "    longitude=longitude_widget.value,\n",
    "    rocktype=rocktype_widget.value,\n",
    "    rockclass=rockclass_widget.value,\n",
    "    mineral=mineral_widget.value,\n",
    "    material=material_widget.value,\n",
    "    inclusiontype=inclusiontype_widget.value,\n",
    "    sampletech=sampletech_widget.value,\n",
    "    element=element_widget.value,\n",
    "    elementtype=elementtype_widget.value,\n",
    "    value=value_widget.value,\n",
    "    title=title_widget.value,\n",
    "    publicationyear=publicationyear_widget.value,\n",
    "    doi=doi_widget.value,\n",
    "    firstname=firstname_widget.value,\n",
    "    lastname=lastname_widget.value,\n",
    "    agemin=agemin_widget.value,\n",
    "    agemax=agemax_widget.value,\n",
    "    geoage=geoage_widget.value,\n",
    "    geoageprefix=geoageprefix_widget.value,\n",
    "    lab=lab_widget.value\n",
    ")\n",
    "\n",
    "# Check if the key \"Data\" exists in the filtered_samples_combined dictionary\n",
    "if 'data' in filtered_samples_combined:\n",
    "    print(\"\\n\")\n",
    "    # Print each item in the list of dictionaries under the key \"Data\"\n",
    "    for item in filtered_samples_combined['data']:\n",
    "        print(str(item))\n",
    "    print(\"\\n\")\n",
    "else:\n",
    "    print(\"No data found or unexpected data structure\", \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the key \"Data\" exists in the dictionary \"filtered_samples_combined\" and if its value is not empty\n",
    "if \"data\" in filtered_samples_combined and filtered_samples_combined[\"data\"]:\n",
    "    \n",
    "    # Extract the \"SampleID\" values from the list of dictionaries in the \"Data\" key\n",
    "    sampling_feature_ids = [sample[\"sampleID\"] for sample in filtered_samples_combined[\"data\"]]\n",
    "    \n",
    "    # Print the extracted SampleIDs\n",
    "    print(\"\\n\", \"The extracted SampleIDs are:\")\n",
    "    \n",
    "    # Print the SampleIDs in groups of 10 with a line break after each group\n",
    "    for i in range(0, len(sampling_feature_ids), 10):\n",
    "        print(sampling_feature_ids[i:i+10])\n",
    "\n",
    "    print(\"\\n\")\n",
    "    \n",
    "else:\n",
    "    print(\"No data found or unexpected data structure\", \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Table of contects](#table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a name=\"extract2\"></a>Extract all the data using the SampleID's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; max-width: 850px\">\n",
    "\n",
    "This Python code is designed to collect and store data from the GEOROC database. It begins by creating an empty DataFrame, measurement_data, and a progress bar for tracking the data retrieval process. As it cycles through each sampling_feature_id, it sends a request to the API to pull corresponding measurement data, storing it in a temporary DataFrame, df. If data is found, a SampleID column is added to df and this data is then appended to measurement_data. The progress bar is updated after each iteration to provide real-time tracking of the data retrieval process.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame to store all measurement data\n",
    "measurement_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the search keys defined above (in case you have forgotten or need to overwrite them)\n",
    "#selected_keys_metadata = ['sampleName', 'latitude', 'longitude']\n",
    "#selected_keys_data = ['itemName', 'itemGroup', 'value', 'unit']\n",
    "\n",
    "# Define the progress bar and the label widgets\n",
    "progress_bar = IntProgress(value=0, min=0, max=len(sampling_feature_ids), \n",
    "                           style={'bar_color': 'maroon'}, \n",
    "                           orientation='horizontal')\n",
    "progress_label = Label(value='Loading: 0/' + str(len(sampling_feature_ids)), \n",
    "                       layout=Layout(margin='0 20px 0 0'))\n",
    "\n",
    "# Put the label and progress bar in a horizontal box\n",
    "progress_display = HBox([progress_label, progress_bar])\n",
    "\n",
    "# Display the progress bar and label\n",
    "display(progress_display)\n",
    "\n",
    "# Iterate over the list of SamplingFeatureIDs\n",
    "for index, sampling_feature_id in enumerate(sampling_feature_ids):\n",
    "    # Get the selected keys from the checkboxes\n",
    "    selected_keys = get_selected_keys(checkboxes)\n",
    "\n",
    "    # Get the measurement data for the current SamplingFeatureID using the selected keys\n",
    "    df = get_measurement_data(my_api.api.api_key, sampling_feature_id, selected_keys_data, selected_keys_metadata)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # Check if the dataframe is not empty and not None\n",
    "    if df is not None and not df.empty:\n",
    "        # Add the SampleID to the dataframe\n",
    "        df['SampleID'] = sampling_feature_id\n",
    "\n",
    "        # Append the dataframe to the measurement_data DataFrame\n",
    "        measurement_data = measurement_data._append(df, ignore_index=True)\n",
    "\n",
    "    # Update the progress bar value and description\n",
    "    progress_bar.value = index + 1\n",
    "    progress_label.value = f'Loading: {progress_bar.value}/{len(sampling_feature_ids)}'\n",
    "\n",
    "# Set the progress bar color to green when done\n",
    "progress_bar.style.bar_color = 'green'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Table of contects](#table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a name=\"rawdata\"></a>The raw dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; max-width: 850px\">\n",
    "\n",
    "Looking at this dataset, it seems that it is in a \"long\" format, where each row represents a specific measurement for a specific geochemical item from a particular sample. The \"NaN\" values for \"Latitude\", \"Longitude\", and \"SampleName\" are redundant in the rows below the first row of each sample. For each unique \"SampleID\", these values remain the same. Hence, the data needs to be cleaned and transformed into a \"wide\" format, which is more suitable for analysis and visualization.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the maximum number of rows to display in pandas DataFrame\n",
    "pd.set_option('display.max_rows', None)\n",
    "# Set the maximum number of columns to display in pandas DataFrame\n",
    "pd.set_option('display.max_columns', None)\n",
    "# set the maximum column width to 100 characters\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the raw dataset\n",
    "measurement_data.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a name=\"strucdata\"></a>Structure and pivot the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; max-width: 850px\">\n",
    "\n",
    "This Python code segment organizes and prepares the measurement data collected from the GEOROC database for further analysis and visualization. It does so by grouping, aggregating, and reformatting the data to a more manageable form.\n",
    "\n",
    "First, the measurement data is grouped by SampleID and Item_Name using the groupby function. Each group's Values are collected into a list.\n",
    "\n",
    "Then, the grouped data is transformed into a pivot table using the pivot function, where each unique SampleID forms a row and each unique Item_Name becomes a column. The Values in each cell are the corresponding  values for that SampleID and Item_Name.\n",
    "\n",
    "However, because these values are currently stored in lists (even though each list contains only one item), a loop is used to extract each single-item list's single element, giving us a simpler table where each cell contains a single value instead of a list.\n",
    "\n",
    "To enrich our table, additional information like 'Longitude', 'Latitude', 'Units', 'Item_Group', and 'SampleName' for each 'SampleID' is extracted from the original data and added to the pivot table through a merge operation. The drop_duplicates function ensures that only unique SampleIDs are used when retrieving this additional information.\n",
    "\n",
    "Finally, the table (DataFrame) is displayed, with options set to show all rows and columns without truncation. This resulting table, final_df, is a cleaned, organized, and enriched version of our measurement data, making it more convenient for analysis and visualization.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Item_Name, Units, and Item_Group into a single column\n",
    "measurement_data['Item'] = measurement_data['itemName'] + ' [' + measurement_data['unit'] + '] [' + measurement_data['itemGroup'] + ']'\n",
    "\n",
    "# Group and aggregate the measurement data\n",
    "grouped_data = measurement_data.groupby(['SampleID', 'Item'])['value'].apply(list).reset_index()\n",
    "\n",
    "# Pivot the DataFrame\n",
    "pivot_df = grouped_data.pivot(index='SampleID', columns='Item', values='value')\n",
    "\n",
    "# Now we convert the lists into individual elements (since there is only one entry per group)\n",
    "for col in pivot_df.columns:\n",
    "    pivot_df[col] = pivot_df[col].str[0]\n",
    "\n",
    "# Extract 'Longitude', 'Latitude', and 'SampleName' for each 'SampleID'\n",
    "additional_columns_df = measurement_data.drop_duplicates(\n",
    "    subset='SampleID')[['SampleID', 'sampleName', 'longitude', 'latitude']]\n",
    "\n",
    "# Merge the data with the original data to add the additional columns\n",
    "final_df = pd.merge(additional_columns_df, pivot_df.reset_index(), on='SampleID', how='left')\n",
    "\n",
    "# Reset the index\n",
    "final_df.reset_index(drop=True, inplace=True)\n",
    "final_df.columns = final_df.columns.str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the final_df DataFrame\n",
    "final_df.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Table of contects](#table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a name=\"sort\"></a>Sort columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; max-width: 850px\">\n",
    "\n",
    "The code begins by designating a list of key column names, including 'SampleID' and various geochemical components, to be prioritized at the top of our DataFrame. A list of remaining columns is created, and both lists are combined to establish a new column order. Applying this new order with the 'reindex' method, we generate a restructured DataFrame. Unnecessary columns such as 'Units', 'Item_Group', and 'SampleName' are then removed using the 'drop' method. The result is a streamlined, reorganized DataFrame ready for geochemical analysis, enhancing data clarity and processing.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of columns that we want to move to the front\n",
    "columns_to_move = ['SIO2_[WT%]_[mj]', 'TIO2_[WT%]_[mj]', 'AL2O3_[WT%]_[mj]', 'FEOT_[WT%]_[mj]', \n",
    "                   'MGO_[WT%]_[mj]', 'CAO_[WT%]_[mj]', 'NA2O_[WT%]_[mj]', 'K2O_[WT%]_[mj]', \n",
    "                   'P2O5_[WT%]_[mj]','LOI_[WT%]_[mj]', 'H2O_[WT%]_[mj]', 'CO2_[WT%]_[mj]', \n",
    "                   'S_[WT%]_[mj]', 'CL_[WT%]_[mj]', 'F_[WT%]_[mj]', 'CO1_[WT%]_[mj]', \n",
    "                   'CH4_[WT%]_[mj]', 'D18O_[VS_SMOW]_[is]', 'DD_[VS_SMOW]_[is]']\n",
    "\n",
    "# Create a new list of columns that contains the remaining columns in their original order\n",
    "remaining_columns = [c for c in final_df.columns if c not in columns_to_move]\n",
    "\n",
    "# Combine the two lists to get the new column order\n",
    "new_column_order = remaining_columns + columns_to_move\n",
    "\n",
    "# Apply the new column order\n",
    "final_df_sort = final_df.reindex(columns=new_column_order)\n",
    "\n",
    "final_df_sort.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a name=\"plotmap\"></a>Plot the data on a map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; max-width: 850px\">\n",
    "\n",
    "This Python code section uses GeoPandas, matplotlib, and contextily libraries to create a geographical map. Specifically, the script plots the coordinates corresponding to different SampleIDs from the final_df DataFrame onto a map.\n",
    "\n",
    "First, the code creates a GeoPandas DataFrame, converting the longitude and latitude columns in final_df into spatial data (geometries). It sets the initial coordinate reference system (CRS) to WGS84 (EPSG:4326), a commonly used geographical coordinate system.\n",
    "\n",
    "To make the data compatible with the basemap, which is provided by contextily and uses a different CRS (Web Mercator, EPSG:3857), the GeoPandas DataFrame is reprojected to this new CRS.\n",
    "\n",
    "Next, a matplotlib figure is created to serve as the base map. A loop plots each sample's coordinates as a red triangular marker on the map, using the reprojected x and y coordinates from the geometries.\n",
    "\n",
    "To ensure all samples appear on the map, the map's extent is set to cover slightly beyond the minimum and maximum x and y coordinates of the data. An OceanBasemap from the Esri provider, accessed through contextily, is added to provide geographic context.\n",
    "\n",
    "Each sample is then labeled on the map with its SampleID using a second loop, with text position adjustments to avoid overlaps.\n",
    "\n",
    "The plot is further customized with a title, axis labels, and a figure-level description of the dredge haul locations.\n",
    "\n",
    "Finally, the figure is saved as a PNG file and displayed within the notebook.\n",
    "\n",
    "This code provides a clear spatial representation of the SampleIDs' locations from the final_df DataFrame. In this context, it reproduces a geographic plot from the publication by Garcia, M. O., et al. (1989), enhancing the understanding of the geochemical data from the Hawaiian submarine tholeiitic glasses study.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coordinates_on_map(final_df_sort):\n",
    "    # Create a geopandas dataframe\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        final_df_sort,\n",
    "        geometry=gpd.points_from_xy(final_df_sort.longitude, final_df_sort.latitude))\n",
    "    gdf.crs = 'EPSG:4326'  # Set the initial CRS (Coordinate Reference System) to WGS84\n",
    "\n",
    "    # Reproject the data to match the CRS used by contextily\n",
    "    gdf_web_mercator = gdf.to_crs(epsg=3857)\n",
    "\n",
    "    # Create the base map\n",
    "    fig = plt.figure(figsize=(20, 10))  # adjust as needed\n",
    "    gs = GridSpec(1, 2, width_ratios=[1, 1])\n",
    "\n",
    "    # plot on first subplot\n",
    "    ax1 = plt.subplot(gs[0])\n",
    "    for _, row in gdf_web_mercator.iterrows():\n",
    "        ax1.scatter(\n",
    "            row['geometry'].x,\n",
    "            row['geometry'].y,\n",
    "            color='red',\n",
    "            edgecolors='black',\n",
    "            marker='^',\n",
    "            s=25\n",
    "        ) \n",
    "\n",
    "    ax1.set_xlim(gdf_web_mercator.total_bounds[0] - 60000, gdf_web_mercator.total_bounds[2] + 60000)\n",
    "    ax1.set_ylim(gdf_web_mercator.total_bounds[1] - 70000, gdf_web_mercator.total_bounds[3] + 12000)\n",
    "    ctx.add_basemap(ax1, source=ctx.providers.Esri.OceanBasemap, zoom='auto')\n",
    "    ax1.set_title('Map of the island of Hawaii', fontsize=16)\n",
    "    ax1.set_xlabel('Longitude')\n",
    "    ax1.set_ylabel('Latitude')\n",
    "\n",
    "    texts = []\n",
    "    for _, row in gdf_web_mercator.iterrows():\n",
    "        texts.append(\n",
    "            plt.text(\n",
    "                row['geometry'].x,\n",
    "                row['geometry'].y,\n",
    "                str(row['sampleName']),\n",
    "                fontsize=8,\n",
    "                color='black',\n",
    "                ha='center')\n",
    "        )\n",
    "    adjust_text(texts)\n",
    "\n",
    "    description = \"Dredge haul locations are shown by the dot symbols for each volcano.\"\n",
    "    plt.figtext(0.5, 0.02, description, ha='center', fontsize=10)\n",
    "\n",
    "    # plot png image on second subplot\n",
    "    ax2 = plt.subplot(gs[1])\n",
    "    img = mpimg.imread('grafics/Hawaii_pub.png')  # specify the path to your png image\n",
    "    ax2.imshow(img, cmap='gray')\n",
    "    ax2.axis('off')  # to hide the axis\n",
    "\n",
    "    # Save and show the map\n",
    "    plt.savefig(\"plot_hawaii.png\")\n",
    "    plt.show()\n",
    "\n",
    "# Plot coordinates on the map using the measurement_data DataFrame\n",
    "plot_coordinates_on_map(final_df_sort)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Table of contects](#table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a name=\"plotfeotS\"></a> Plot FeO* against S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; max-width: 850px\">\n",
    "\n",
    "This code section utilizes matplotlib and seaborn libraries to generate a scatter plot for 'FeO*' vs. 'S' values in the final_df DataFrame, while also marking certain data points with ellipses.\n",
    "\n",
    "Firstly, a list of columns to be excluded from the plot and a list of markers and colors for the scatter plot are defined. These markers and colors are used to visually distinguish different groups of data in the plot.\n",
    "\n",
    "In the next part, specific SampleIDs are chosen to be highlighted with ellipses. For each ellipse, initial parameters (center, width, height, and angle) are set to None or zero.\n",
    "\n",
    "The code then sets the size of the plot figure and starts a loop through each row of the final_df DataFrame. Within the loop, each data point is plotted on the scatter plot according to its 'FEOT' and 'S' values. The marker style and color are selected based on the loop index.\n",
    "\n",
    "For the rows where SampleID matches one of the defined sample IDs for ellipses, the script checks whether the corresponding ellipse parameters have been set. If not, they are set to specific values. Then, an ellipse is created with these parameters and added to the plot. Each ellipse is created using the matplotlib.patches.Ellipse function, and it is customized with different edge colors, line styles, and without a face color.\n",
    "\n",
    "The code continues this process for all three ellipses, distinguishing each one with a different linestyle (dashed, dotted, and dashdot).\n",
    "\n",
    "After all data points have been plotted and ellipses added, the plot is further customized with a legend, title, and axis labels. The axes' range is optionally restricted to enhance visibility of the plotted data points and ellipses.\n",
    "\n",
    "Finally, the figure is saved as a PNG file and displayed in the notebook.\n",
    "\n",
    "This script provides a visual exploration of the relationship between 'FeO*' and 'S' values in the final_df DataFrame, with additional emphasis on specific sample IDs represented by ellipses. This helps in visualizing and interpreting important characteristics or groupings within the dataset.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to get the marker based on the sample name\n",
    "def get_marker(sample_name):\n",
    "    if 'ML' in sample_name:\n",
    "        return '^'\n",
    "    elif 'KIL' in sample_name:\n",
    "        return 'o'\n",
    "    elif 'LO' in sample_name:\n",
    "        return 's'\n",
    "    elif 'H-1' in sample_name:\n",
    "        return 'd'\n",
    "    elif 'HP' in sample_name:\n",
    "        return 'D'\n",
    "    elif 'KO' in sample_name:\n",
    "        return '.'\n",
    "    elif 'MK' in sample_name:\n",
    "        return '*'\n",
    "    else:\n",
    "        return '<'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables for the ellipses\n",
    "ellipse_params = [\n",
    "    ((10.7, 0.05), 1.95, 0.05, 0, 'solid'),\n",
    "    ((10.8, 0.126), 1.6, 0.1, 0, 'dashed'),\n",
    "    ((12, 0.125), 1.2, 0.13, 0, 'dotted'),\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 6))  # Adjust the figure size as needed\n",
    "\n",
    "for i in range(len(final_df_sort)):\n",
    "    sample_name = final_df_sort['sampleName'].iloc[i]\n",
    "    marker = get_marker(sample_name)\n",
    "    sns.scatterplot(ax=axes[0], \n",
    "                    x=final_df_sort['FEOT_[WT%]_[mj]'].iloc[i:i+1], \n",
    "                    y=final_df_sort['S_[WT%]_[mj]'].iloc[i:i+1],\n",
    "                    marker=marker, \n",
    "                    color='k')\n",
    "\n",
    "# Create and add ellipses to the plot\n",
    "for center, width, height, angle, linestyle in ellipse_params:\n",
    "    ellipse = Ellipse(center, \n",
    "                      width, \n",
    "                      height, \n",
    "                      angle=angle, \n",
    "                      edgecolor='black', \n",
    "                      facecolor='none',\n",
    "                      linestyle=linestyle)\n",
    "    axes[0].add_patch(ellipse)\n",
    "\n",
    "axes[0].text(11.7, 0.025, 'MAUNA LOA', ha='center', fontsize=13)\n",
    "axes[0].text(9.9, 0.16, 'KILAUEA', ha='center', fontsize=13)\n",
    "axes[0].text(12.6, 0.175, 'LOIHI', ha='center', fontsize=13)\n",
    "\n",
    "axes[0].set_title(\"FeO* vs. S\")\n",
    "axes[0].set_xlabel(\"FeO* [Wt%]\")\n",
    "axes[0].set_ylabel(\"S [Wt%]\")\n",
    "\n",
    "axes[0].set_xlim(9, 13)\n",
    "axes[0].set_ylim(0, 0.25)\n",
    "\n",
    "img = mpimg.imread('grafics/S_vs_FeOT_pub.png')\n",
    "\n",
    "axes[1].imshow(img, cmap='gray')\n",
    "axes[1].axis('off')  # Optionally turn off the axis for the image subplot\n",
    "\n",
    "plt.savefig('plot_FEOT_vs_S.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; max-width: 850px\">\n",
    "\n",
    "> <a name=\"hint4\"></a> **Hint**: \n",
    "> In the official publication, additional data from another publication were used for the analyses and the visualisations. Therefore, some data points are not available because the geochemical values were not added by third party publications.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Table of contects](#table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a name=\"plottas\"></a> Plot the data in the TAS diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; max-width: 850px\">\n",
    "\n",
    "This code creates a scatter plot to visualize the relationship between the values of $SiO_2$ and $K_2O+Na_2O$ in a DataFrame named final_df.\n",
    "\n",
    "First, a new column 'K2O+NA2O' is added to the final_df DataFrame, which represents the sum of the values in the $K_2O$ and $Na_2O$ columns for each row.\n",
    "\n",
    "Next, lists of markers and colors are created to distinguish the individual data points in the scatter plot. These lists are created such that different groups of data points get different markers and colors.\n",
    "\n",
    "Then, the figure size is set, and a scatter plot for each data point is created by iterating through the rows of final_df. Each data point is placed on the scatter plot according to its $SiO_2$ and $K_2O+Na_2O$ values. The marker and color for each point are selected based on the index in the loop.\n",
    "\n",
    "Additionally, a line is added to the plot that separates the data points into two groups, labeled 'ALKALIC' and 'THOLEIITIC'. The line is drawn by defining two points specified by their x and y coordinates, and a line is drawn between these points.\n",
    "\n",
    "Finally, a title and axis labels are added to the plot, and the range of the x and y axes is optionally restricted. The plot is then displayed.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a new column 'K2O+NA2O' to the final_df DataFrame\n",
    "final_df_sort['K2O_[WT%]_[mj]+NA2O_[WT%]_[mj]'] = final_df_sort['K2O_[WT%]_[mj]'] + final_df_sort['NA2O_[WT%]_[mj]']\n",
    "\n",
    "# Initialize variables for the ellipses\n",
    "ellipse_params = [\n",
    "    ((52.3, 2.8), 0.9, 0.65, 0, 'solid'),\n",
    "    ((49, 3.0), 1.5, 0.3, 0, 'dotted'),\n",
    "    ((51.25, 2.95), 1, 0.9, 0, 'dashed'),\n",
    "]\n",
    "\n",
    "# Set the figure size and create two subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))  # Adjust the figure size as needed\n",
    "\n",
    "# Loop through the rows of the final_df DataFrame\n",
    "for i in range(len(final_df_sort)):\n",
    "    sample_name = final_df_sort['sampleName'].iloc[i]\n",
    "    marker = get_marker(sample_name)\n",
    "    # Plot the scatterplot on the first subplot\n",
    "    sns.scatterplot(ax=axes[0], \n",
    "                    x=final_df_sort['SIO2_[WT%]_[mj]'].iloc[i:i+1], \n",
    "                    y=final_df_sort['K2O_[WT%]_[mj]+NA2O_[WT%]_[mj]'].iloc[i:i+1],\n",
    "                    marker=marker, \n",
    "                    color='k', \n",
    "                    s=45)\n",
    "\n",
    "# Add ellipses to the scatterplot\n",
    "for center, width, height, angle, linestyle in ellipse_params:\n",
    "    ellipse = Ellipse(center, \n",
    "                      width, \n",
    "                      height, \n",
    "                      angle=angle, \n",
    "                      edgecolor='black', \n",
    "                      facecolor='none',\n",
    "                      linestyle=linestyle)\n",
    "    axes[0].add_patch(ellipse)\n",
    "\n",
    "# Adding a line and text annotations to the first subplot\n",
    "x_values = [48, 50.3]\n",
    "y_values = [3.15, 3.8]\n",
    "axes[0].plot(x_values, y_values, color='k', linewidth=0.5)\n",
    "axes[0].text(49.2, 3.6, 'ALKALIC', ha='right', fontsize=14)\n",
    "axes[0].text(51.5, 3.6, 'THOLEIITIC', ha='right', fontsize=14)\n",
    "\n",
    "# Adding title , ellipses and axis labels to the first subplot\n",
    "axes[0].text(52.4, 3.15, 'MAUNA \\n LOA', ha='center', fontsize=10)\n",
    "axes[0].text(50.6, 3.35, 'KILAUEA', ha='center', fontsize=10)\n",
    "axes[0].text(48.5, 2.75, 'LOIHI', ha='center', fontsize=10) \n",
    "\n",
    "axes[0].set_title(\"$SiO_2$ vs. $K_2O+Na_2O$\")\n",
    "axes[0].set_xlabel(\"$SiO_2$ [Wt%]\")\n",
    "axes[0].set_ylabel(\"$K_2O+Na_2O$ [Wt%]\")\n",
    "\n",
    "# Optionally, restricting the range of the axes\n",
    "axes[0].set_xlim(48, 53)\n",
    "axes[0].set_ylim(2.4, 3.8)\n",
    "\n",
    "# Load the image\n",
    "img = mpimg.imread('grafics/TAS_pub.png')\n",
    "\n",
    "# Display the image in the second subplot\n",
    "axes[1].imshow(img, cmap='gray')\n",
    "axes[1].axis('off')  # Optionally turn off the axis for the image subplot\n",
    "\n",
    "# Save the plot as an image\n",
    "plt.savefig('plot_TAS.png')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; max-width: 850px\">\n",
    "\n",
    "> <a name=\"hint5\"></a> **Hint**: \n",
    "> In the official publication, additional data from another publication were used for the analyses and the visualisations. Therefore, some data points are not available because the geochemical values were not added by third party publications.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"api-download\"></a>**Excursion 1**: API download to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://api-test.georoc.eu/api/v1/download/filtered\"\n",
    "\n",
    "params = {\n",
    "    'doi': '10.1029/JB094iB08p10525'\n",
    "    }\n",
    "\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"DIGIS-API-ACCESSKEY\": my_api.api.api_key\n",
    "    }\n",
    "\n",
    "base_url = f\"https://api-test.georoc.eu/api/v1/download/filtered\"\n",
    "\n",
    "response = requests.get(base_url, headers=headers, params=params)\n",
    "\n",
    "filename = 'dataset/GEOROC-API.csv'\n",
    "with open(filename, mode='wb') as localfile:\n",
    "    localfile.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/GEOROC-API.csv', index_col=0)\n",
    "\n",
    "df_cleaned = df.dropna(axis=1, how='all')\n",
    "\n",
    "df_cleaned.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Table of contects](#table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"excursion\"></a> **Excursion 2**: EarthChem API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; max-width: 850px\">\n",
    "\n",
    "<img src=\"https://earthchem.org/wp-content/uploads/2020/10/earthchem_full_logo_black.png\" style=\"height:200px\" align=\"left\"/> <br><br><br><br><br><br><br><br><br><br>\n",
    "\n",
    "The EarthChem database is a comprehensive resource for geochemical and petrological data. It provides access to a wide range of data, including elemental compositions, isotopic ratios, and rock classifications. To facilitate access to the data, EarthChem also provides an API. This API allows researchers to retrieve, analyze, and integrate data into their own applications. The EarthChem API provides flexible query capabilities and enables detailed exploration of the data. It promotes scientific discovery and collaboration in the geosciences.\n",
    "\n",
    "First, the URL is defined through which the requests are to be sent to the EarthChem API. In this case it is \"http://portal.earthchem.org/restsearchservice\".\n",
    "\n",
    "Then the parameters that will be used for the API request are defined. The DOI (\"10.1029/JB094iB08p10525\") is specified to be searched for. The search type (\"rowdata\"), output type (\"json\"), and default elements (\"yes\") are also specified.\n",
    "\n",
    "The request to the API is sent using the requests.get() command, passing the URL and parameters. The result is stored in the response variable.\n",
    "\n",
    "The response object (response) is converted to JSON format to extract the data. The response.json() function returns a Python object that contains the extracted data.\n",
    "\n",
    "The extracted data is then converted into a Pandas DataFrame using pd.json_normalize() to obtain a tabular structure.\n",
    "\n",
    "Finally, the DataFrame is saved to a CSV file named \"EarthChem.csv\" located in the \"dataset\" directory.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://portal.earthchem.org/restsearchservice\"\n",
    "\n",
    "params = {\n",
    "    'doi': '10.1029/JB094iB08p10525',\n",
    "    'searchtype': 'rowdata',\n",
    "    'outputtype': 'json',\n",
    "    'standarditems': 'yes'\n",
    "}\n",
    "\n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "data = response.json()\n",
    "df = pd.json_normalize(data)\n",
    "\n",
    "df.to_csv('dataset/EarthChem.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; max-width: 850px\">\n",
    "\n",
    "With pd.read_csv() the CSV file is read and saved into a Pandas DataFrame named df.\n",
    "\n",
    "Then df_cleaned is created by removing all columns that consist only of missing values. Here dropna() is used, where axis=1 indicates that columns should be removed, and how='all' indicates that a column is removed if it consists solely of missing values.\n",
    "\n",
    "Finally, the cleaned DataFrame df_cleaned is output with print() to display the results.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/EarthChem.csv', index_col=0)\n",
    "\n",
    "df_cleaned = df.dropna(axis=1, how='all')\n",
    "\n",
    "df_cleaned.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Table of contects](#table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"refs\"></a>References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; max-width: 850px\">\n",
    "\n",
    "[1] **Garcia, M. O., Muenow, D. W., Aggrey, K. E., and O'Neil, J. R. (1989)**, Major element, volatile, and stable isotope geochemistry of Hawaiian submarine tholeiitic   glasses, J. Geophys. Res., 94( B8), 10525– 10538, doi:10.1029/JB094iB08p10525. \n",
    "\n",
    "[2] **EarthChem Systems** (30.06.2023): EarthChem Database. Interdisciplinary Earth Data Alliance (IEDA). [Link to database](https://www.earthchem.org/). Accessed 30.06.2023.\n",
    "\n",
    "[3] **requests** - Python HTTP library for humans. [Online]. Available: https://requests.readthedocs.io\n",
    "\n",
    "[4] **json** - This is part of Python's standard library. Python Software Foundation. Python Language Reference, version 3.x. Available at http://www.python.org\n",
    "\n",
    "[5] **pandas** - Wes McKinney. Data Structures for Statistical Computing in Python, Proceedings of the 9th Python in Science Conference, 51-56 (2010) [Online]. Available: https://pandas.pydata.org\n",
    "\n",
    "[6] **geopandas** - GeoPandas developers. GeoPandas: Python tools for geographic data [Online]. Available: https://geopandas.org\n",
    "\n",
    "[7] **seaborn** - Michael Waskom, Olga Botvinnik, Drew O’Kane, Paul Hobson, Joel Ostblom, Saulius Lukauskas, ... & Tom Augspurger. (2020, October 4). mwaskom/seaborn: v0.11.0 (Version v0.11.0). Zenodo. http://doi.org/10.5281/zenodo.4019147\n",
    "\n",
    "[8] **matplotlib** - John D. Hunter. Matplotlib: A 2D Graphics Environment, Computing in Science & Engineering, 9, 90-95 (2007), DOI:10.1109/MCSE.2007.55\n",
    "\n",
    "[9] **contextily** - Darribas, D., Arribas-Bel, D., Nshan, B., & van den Bosch, M. (2020). contextily: context geo-tiles in Python. Journal of Open Source Software, 5(55), 2302. https://doi.org/10.21105/joss.02302\n",
    "\n",
    "[10] **adjustText** - Ilya Flyamer. (2016). adjustText: A small library for automatically adjusting text position in matplotlib plots to minimize overlaps. Zenodo. http://doi.org/10.5281/zenodo.4922517\n",
    "\n",
    "[11] **ipywidgets** - Project Jupyter. (2017). ipywidgets: Interactive HTML widgets for Jupyter notebooks and the IPython kernel. Zenodo. https://doi.org/10.5281/zenodo.836874\n",
    "\n",
    "[Back to Table of contects](#table)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"qrcode\"></a>QR code for accessing this Jupyter notebook on Binder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/digis-georoc/Georoc_jupyter/main/grafics/BINDER_JUPYTER_QR.png\" style=\"height:610px\" align=\"left\"/> <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a name=\"hint3\"></a>Hint:\n",
    "- In some cases, Binder may not work the first time it is started. Then simply restart the link again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"follow\"></a>Follow us\n",
    "\n",
    "[Visit official GEOROC website](https://georoc.eu/)\n",
    "\n",
    "<a id=\"follow-button\" class=\"btn\" title=\"Follow @DIGISgeo on Twitter\" href=\"https://twitter.com/intent/follow?original_referer=https%3A%2F%2Fgeoroc.eu%2F&amp;ref_src=twsrc%5Etfw%7Ctwcamp%5Ebuttonembed%7Ctwterm%5Efollow%7Ctwgr%5EDIGISgeo&amp;region=follow_link&amp;screen_name=DIGISgeo\"><i></i><span class=\"label\" id=\"l\">Follow <b>@DIGISgeo</b></span></a>\n",
    "\n",
    "If you are considering installing Jupyter Notebook, <br> you can visit our [installations instructions](https://github.com/digis-georoc/Georoc_jupyter/tree/main#local)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Table of contects](#table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as ctx\n",
    "from adjustText import adjust_text\n",
    "from ipywidgets import widgets\n",
    "from ipywidgets import Layout\n",
    "from ipywidgets import IntProgress, Layout, HBox, Label\n",
    "from ipywidgets import Button\n",
    "from functions.widgets import *\n",
    "from functions.georoc_api import GeoRocAPI\n",
    "from functions.app import MyApp\n",
    "from functions.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_app = MyApp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_api_connection():\n",
    "    endpoint = \"ping\"\n",
    "    response = my_app.api.api_query(endpoint)\n",
    "\n",
    "    if response is not None:\n",
    "        print(\"Connection to API server successful!\\n\")\n",
    "    else:\n",
    "        print(\"Failed to connect to API server!\\n\")\n",
    "        exit(1)\n",
    "\n",
    "check_api_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(grid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_samples_combined = my_app.api.get_filtered_samples(\n",
    "    limit=limit_widget.value, \n",
    "    offset=offset_widget.value, \n",
    "    location1=location1_widget.value,\n",
    "    location2=location2_widget.value,\n",
    "    location3=location3_widget.value,\n",
    "    setting=setting_widget.value,\n",
    "    latitude=latitude_widget.value,\n",
    "    longitude=longitude_widget.value,\n",
    "    rocktype=rocktype_widget.value,\n",
    "    rockclass=rockclass_widget.value,\n",
    "    mineral=mineral_widget.value,\n",
    "    material=material_widget.value,\n",
    "    inclusiontype=inclusiontype_widget.value,\n",
    "    sampletech=sampletech_widget.value,\n",
    "    element=element_widget.value,\n",
    "    elementtype=elementtype_widget.value,\n",
    "    value=value_widget.value,\n",
    "    title=title_widget.value,\n",
    "    publicationyear=publicationyear_widget.value,\n",
    "    doi=doi_widget.value,\n",
    "    firstname=firstname_widget.value,\n",
    "    lastname=lastname_widget.value,\n",
    "    agemin=agemin_widget.value,\n",
    "    agemax=agemax_widget.value,\n",
    "    geoage=geoage_widget.value,\n",
    "    geoageprefix=geoageprefix_widget.value,\n",
    "    lab=lab_widget.value\n",
    ")\n",
    "\n",
    "if 'Data' in filtered_samples_combined:\n",
    "    print(\"\\n\")\n",
    "    for item in filtered_samples_combined['Data']:\n",
    "        print(str(item))\n",
    "    print(\"\\n\")\n",
    "else:\n",
    "    print(\"No data found or unexpected data structure\", \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"Data\" in filtered_samples_combined and filtered_samples_combined[\"Data\"]:\n",
    "    sampling_feature_ids = [sample[\"SampleID\"] for sample in filtered_samples_combined[\"Data\"]]\n",
    "    \n",
    "    print(\"\\n\", \"The extracted SampleIDs are:\")\n",
    "    \n",
    "    # Drucken Sie die SampleIDs in Gruppen von 10 mit einem Zeilenumbruch nach jeder Gruppe\n",
    "    for i in range(0, len(sampling_feature_ids), 10):\n",
    "        print(sampling_feature_ids[i:i+10])\n",
    "\n",
    "    print(\"\\n\")\n",
    "    \n",
    "else:\n",
    "    print(\"No data found or unexpected data structure\", \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame to store all measurement data\n",
    "measurement_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress_bar = widgets.IntProgress(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=len(sampling_feature_ids),\n",
    "    description='Loading:',\n",
    "    bar_style='info',\n",
    "    style={'bar_color': 'maroon'},\n",
    "    orientation='horizontal'\n",
    ")\n",
    "\n",
    "display(progress_bar)\n",
    "\n",
    "# Iterate over the list of SamplingFeatureIDs\n",
    "for index, sampling_feature_id in enumerate(sampling_feature_ids):\n",
    "    # Get the selected keys from the checkboxes\n",
    "    selected_keys = get_selected_keys(checkboxes)\n",
    "\n",
    "    # Get the measurement data for the current SamplingFeatureID using the selected keys\n",
    "    df = get_measurement_data(my_app.api.api_key, sampling_feature_id, selected_keys)\n",
    "\n",
    "    # Check if the dataframe is not empty and not None\n",
    "    if df is not None and not df.empty:\n",
    "        # Add the SampleID to the dataframe\n",
    "        df['SampleID'] = sampling_feature_id\n",
    "        \n",
    "        # Append the dataframe to the measurement_data DataFrame\n",
    "        measurement_data = measurement_data._append(df, ignore_index=True)\n",
    "\n",
    "    # Update the progress bar\n",
    "    progress_bar.value = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gruppieren und Aggregieren der Messdaten\n",
    "grouped_data = measurement_data.groupby(['SampleID', 'Item_Name'])['Values'].apply(list).reset_index()\n",
    "\n",
    "# Pivotieren des DataFrames\n",
    "pivot_df = grouped_data.pivot(index='SampleID', columns='Item_Name', values='Values')\n",
    "\n",
    "# Jetzt konvertieren wir die Listen in einzelne Elemente (da es nur einen Eintrag pro Gruppe gibt)\n",
    "for col in pivot_df.columns:\n",
    "    pivot_df[col] = pivot_df[col].str[0]\n",
    "\n",
    "# Extrahieren der 'Longitude', 'Latitude', 'Units', 'Item_Group' und 'SampleName' für jede 'SampleID'\n",
    "additional_columns_df = measurement_data.drop_duplicates(subset='SampleID')[['SampleID', 'Longitude', 'Latitude', 'Units', 'Item_Group', 'SampleName']]\n",
    "\n",
    "# Zusammenführen der Daten mit den ursprünglichen Daten, um die zusätzlichen Spalten hinzuzufügen\n",
    "final_df = pd.merge(pivot_df.reset_index(), additional_columns_df, on='SampleID', how='left')\n",
    "\n",
    "# Zurücksetzen des Index\n",
    "final_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "final_df.style.highlight_null(color='yellow')\n",
    "\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coordinates_on_map(final_df):\n",
    "    # Create a geopandas dataframe\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        final_df,\n",
    "        geometry=gpd.points_from_xy(final_df.Longitude, final_df.Latitude))\n",
    "    gdf.crs = 'EPSG:4326'  # Set the initial CRS (Coordinate Reference System) to WGS84\n",
    "\n",
    "    # Reproject the data to match the CRS used by contextily\n",
    "    gdf_web_mercator = gdf.to_crs(epsg=3857)\n",
    "\n",
    "    # Create the base map\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "    # Plot markers on the map with sample IDs\n",
    "    for _, row in gdf_web_mercator.iterrows():\n",
    "        ax.scatter(\n",
    "            row['geometry'].x,\n",
    "            row['geometry'].y,\n",
    "            color='red',\n",
    "            edgecolors='black',\n",
    "            s=15\n",
    "        )  # Add markers\n",
    "\n",
    "    # Set the map extent to match the data\n",
    "    ax.set_xlim(gdf_web_mercator.total_bounds[0] - 60000, gdf_web_mercator.total_bounds[2] + 60000)\n",
    "    ax.set_ylim(gdf_web_mercator.total_bounds[1] - 70000, gdf_web_mercator.total_bounds[3] + 12000)\n",
    "\n",
    "    # Add satellite imagery from OpenStreetMap\n",
    "    ctx.add_basemap(ax, source=ctx.providers.Esri.OceanBasemap, zoom='auto')\n",
    "\n",
    "    # Add title and axis labels\n",
    "    ax.set_title('Samples in Hawaii', fontsize=16)\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "\n",
    "    # Plot sample IDs with adjustText\n",
    "    texts = []\n",
    "    for _, row in gdf_web_mercator.iterrows():\n",
    "        texts.append(\n",
    "            plt.text(\n",
    "                row['geometry'].x,\n",
    "                row['geometry'].y,\n",
    "                str(row['SampleID']),\n",
    "                fontsize=8,\n",
    "                color='black',\n",
    "                ha='center')\n",
    "        )\n",
    "\n",
    "    # Justiere die Textpositionen\n",
    "    adjust_text(texts)\n",
    "\n",
    "    # Save and show the map\n",
    "    plt.savefig(\"plot_hawaii.png\")\n",
    "    plt.show()\n",
    "\n",
    "# Plot coordinates on the map using the measurement_data DataFrame\n",
    "plot_coordinates_on_map(final_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
